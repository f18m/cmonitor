#!/usr/bin/python3

#
# cmonitor_chart.py
# Originally based on the "njmonchart_aix_v7.py" from Nigel project: http://nmon.sourceforge.net/
#
# Author: Francesco Montorsi
# Created: April 2019
#

import sys
import json
import gzip
import datetime
import zlib
import binascii
import textwrap
import argparse
import getopt
import os
import time

# =======================================================================================================
# CONSTANTS
# =======================================================================================================

VERSION_STRING = "__RPM_VERSION__-__RPM_RELEASE__"

GRAPH_SOURCE_DATA_BAREMETAL = 1
GRAPH_SOURCE_DATA_CGROUP = 2

GRAPH_TYPE_AREA_CHART = 1
GRAPH_TYPE_BUBBLE_CHART = 2

SAVE_DEFLATED_JS_DATATABLES = True
JS_INDENT_SIZE = 2

# see https://developers.google.com/chart/interactive/docs/reference#dateformat
# the idea is that cmonitor_chart will most likely be used to explore short time intervals
# so that day/month/year part is not useful, just the time is useful; in tooltip we also
# reach millisec accuracy:
X_AXIS_DATEFORMAT = "HH:mm:ss"
TOOLTIP_DATEFORMAT = "HH:mm:ss.SSS z"


# =======================================================================================================
# GLOBALs
# =======================================================================================================

verbose = False
g_num_generated_charts = 1
g_next_graph_need_stacking = 0
g_datetime = "localtz"  # can be changed to "UTC" with --utc; FIXME currently we always use just UTC, never localtz...

# =======================================================================================================
# GoogleChartsTimeSeries
# =======================================================================================================


class GoogleChartsTimeSeries(object):
    """
    GoogleChartsTimeSeries is a table of
       t;Y1;Y2;...;YN
    data points for a GoogleCharts graph that is representing the evolution of N quantities over time
    """

    def __init__(self, column_names):
        self.column_names = column_names  # must be a LIST of strings
        self.rows = []  # list of lists with values

    def ISOdatetimeToJSDate(self, date):
        """convert ISO datetime strings like
          "2017-08-21T20:12:30.123"
        to strings like:
          "Date(2017,8,21,20,12,30,123000)"
        which are the datetime representation suitable for JS GoogleCharts, see
        https://developers.google.com/chart/interactive/docs/datesandtimes
        """
        dateAsPythonObj = datetime.datetime.strptime(date, "%Y-%m-%dT%H:%M:%S.%f")

        return "Date(%d,%d,%d,%d,%d,%d,%d)" % (
            dateAsPythonObj.year,
            dateAsPythonObj.month,
            dateAsPythonObj.day,
            dateAsPythonObj.hour,
            dateAsPythonObj.minute,
            dateAsPythonObj.second,
            dateAsPythonObj.microsecond / 1000,  # NOTE: the JavaScript Date() object wants milliseconds
        )

    def addRow(self, row_data_list):
        assert len(row_data_list) == len(self.column_names)

        # convert first column to a GoogleCharts-compatible datetime:
        row_data_list[0] = self.ISOdatetimeToJSDate(row_data_list[0])
        self.rows.append(row_data_list)

    def getRow(self, index):
        return self.rows[index]

    def getListColumnNames(self):
        return self.column_names

    def getNumDataSeries(self):
        # assuming first column is the timestamp, the number of "data series"
        # present in this table is all remaining columns
        return len(self.column_names) - 1

    def writeTo(self, file):
        for r in self.rows:
            # assume first column is always the timestamp:
            row_text = "['Date(%s)'," % r[0]
            row_text += ",".join(str(x) for x in r[1:])
            row_text += "],\n"
            file.write(row_text)

    def toJSONForJS(self):
        ret = "[["  # start 2D JSON array

        # convert 1st column:
        assert self.column_names[0] == "Timestamp"
        ret += '{"type":"datetime","label":"Datetime"},'

        # convert all other columns:
        for colName in self.column_names[1:]:
            ret += '"' + colName + '",'
        ret = ret[:-1]

        # separe first line; start conversion of actual table data:
        ret += "],"

        data = json.dumps(self.rows, separators=(",", ":"))
        data = data[1:]

        return ret + data

    def toDeflatedJSONBase64Encoded(self):
        """Returns this table in JSON format (for JS), deflated using zlib, and represented as a Base64-encoded ASCII string"""
        json_string = self.toJSONForJS()
        json_compressed_bytearray = zlib.compress(json_string.encode(), 9)

        ret = str(binascii.b2a_base64(json_compressed_bytearray))
        return ret[1:]

    def toGoogleChartTable(self, graphName):
        """Writes in the given file the JavaScript GoogleCharts object representing this table"""
        ret_string = ""
        if SAVE_DEFLATED_JS_DATATABLES:
            # to reduce the HTML size save the deflated, serialized JSON of the 2D JS array:
            ret_string += "var deflated_data_base64_%s = %s;\n" % (
                graphName,
                self.toDeflatedJSONBase64Encoded(),
            )

            # then convert it base64 -> JS binary string
            ret_string += "var deflated_data_binary_%s = window.atob(deflated_data_base64_%s);\n" % (graphName, graphName)

            # now inflate it in the browser using "pako" library (https://github.com/nodeca/pako)
            ret_string += "var inflated_data_%s = JSON.parse(pako.inflate(deflated_data_binary_%s, { to: 'string' }));\n" % (graphName, graphName)
        else:
            ret_string += "var inflated_data_%s = %s;\n" % (
                graphName,
                self.toJSONForJS(),
            )

        # finally create the GoogleCharts table from it:
        ret_string += "var data_%s = google.visualization.arrayToDataTable(inflated_data_%s);\n" % (graphName, graphName)

        # add DateFormatter to use custom formatting of the 1st column (like everywhere else we assume first column is the timestamp)
        ret_string += "var date_formatter = new google.visualization.DateFormat({pattern: '%s'});\n" % (TOOLTIP_DATEFORMAT)
        ret_string += "date_formatter.format(data_%s, 0);\n\n" % (graphName)

        return ret_string


# =======================================================================================================
# GoogleChartsGenericTable
# =======================================================================================================


class GoogleChartsGenericTable(object):
    """
    This is the NxM table of
       Y1_1;Y2_1;...;YN_1
       ...
       Y1_M;Y2_M;...;YN_M
    data points for a GoogleCharts graph for M different objects characterized by N features
    """

    def __init__(self, column_names):
        self.column_names = column_names  # must be a LIST of strings
        self.rows = []  # list of lists with values

    def addRow(self, row_data_list):
        assert len(row_data_list) == len(self.column_names)
        self.rows.append(row_data_list)

    def getRow(self, index):
        return self.rows[index]

    def getListColumnNames(self):
        return self.column_names

    def getNumDataSeries(self):
        # assuming first column is the timestamp, the number of "data series"
        # present in this table is all remaining columns
        return len(self.column_names) - 1

    def writeTo(self, file):
        for r in self.rows:
            file.write(",".join(r))

    def toJSONForJS(self):
        ret = "[["  # start 2D JSON array

        # convert all other columns:
        for colName in self.column_names:
            ret += '"' + colName + '",'
        ret = ret[:-1]

        # separe first line; start conversion of actual table data:
        ret += "],"

        data = json.dumps(self.rows, separators=(",", ":"))
        data = data[1:]

        return ret + data

    def toDeflatedJSONBase64Encoded(self):
        """Returns this table in JSON format (for JS), deflated using zlib, and represented as a Base64-encoded ASCII string"""
        json_string = self.toJSONForJS()
        json_compressed_bytearray = zlib.compress(json_string.encode(), 9)

        ret = str(binascii.b2a_base64(json_compressed_bytearray))
        return ret[1:]

    def toGoogleChartTable(self, graphName):
        """Writes in the given file the JavaScript GoogleCharts object representing this table"""
        ret_string = ""
        if SAVE_DEFLATED_JS_DATATABLES:
            # to reduce the HTML size save the deflated, serialized JSON of the 2D JS array:
            ret_string += "var deflated_data_base64_%s = %s;\n" % (
                graphName,
                self.toDeflatedJSONBase64Encoded(),
            )

            # then convert it base64 -> JS binary string
            ret_string += "var deflated_data_binary_%s = window.atob(deflated_data_base64_%s);\n" % (graphName, graphName)

            # now inflate it in the browser using "pako" library (https://github.com/nodeca/pako)
            ret_string += "var inflated_data_%s = JSON.parse(pako.inflate(deflated_data_binary_%s, { to: 'string' }));\n" % (graphName, graphName)
        else:
            ret_string += "var inflated_data_%s = %s;\n" % (
                graphName,
                self.toJSONForJS(),
            )

        # finally create the GoogleCharts table from it:
        ret_string += "var data_%s = google.visualization.arrayToDataTable(inflated_data_%s);\n" % (graphName, graphName)
        return ret_string


# =======================================================================================================
# GoogleChartsGraph
# =======================================================================================================


class GoogleChartsGraph:
    """
    This is a simple object that can generate JavaScript for GoogleChart drawing
    """

    def __init__(
        self,
        button_label="",
        combobox_label="",
        combobox_entry="",
        graph_source=GRAPH_SOURCE_DATA_BAREMETAL,
        graph_type=GRAPH_TYPE_AREA_CHART,
        graph_title="",
        stack_state=False,
        y_axis_title="",
        series_for_2nd_yaxis=[],
        data=None,
    ):
        self.button_label = button_label
        self.combobox_label = combobox_label
        assert (len(self.button_label) == 0 and len(self.combobox_label) > 0) or (len(self.button_label) > 0 and len(self.combobox_label) == 0)
        self.combobox_entry = combobox_entry
        self.source_data = graph_source  # one of GRAPH_TYPE_BAREMETAL or GRAPH_TYPE_CGROUP
        self.graph_type = graph_type
        self.graph_title = graph_title
        self.stack_state = stack_state
        self.y_axis_title = y_axis_title
        self.series_for_2nd_yaxis = series_for_2nd_yaxis
        self.data_table = data  # of type GoogleChartsGenericTable or GoogleChartsTimeSeries
        self.graph_title += ", STACKED graph" if self.stack_state else ""

        # generate new JS name for this graph
        global g_num_generated_charts
        self.js_name = "graph" + str(g_num_generated_charts)
        g_num_generated_charts += 1

    def genGoogleChartJS_AreaChart(self):
        """After the JavaScript line graph data is output, the data is terminated and the graph options set"""
        global g_next_graph_need_stacking

        def __internalWriteAxis(series_indexes, target_axis_index):
            ret = ""
            for i, idx in enumerate(series_indexes, start=0):
                ret += "   %d: {targetAxisIndex:%d}" % (idx, target_axis_index)
                # print("i=%d, idx=%d, target_axis_index=%d" % (i,idx,target_axis_index))
                if i < len(series_indexes):
                    ret += ",\n"
                else:
                    ret += "\n"
            return ret

        ret_string = ""
        ret_string += "var options_%s = {\n" % (self.js_name)
        ret_string += '  chartArea: {left: "5%", width: "85%", top: "10%", height: "80%"},\n'
        ret_string += '  title: "%s",\n' % (self.graph_title)
        ret_string += '  focusTarget: "category",\n'

        # by default this tool plots the top 20 processes; in these cases both tooltips and legend will have up to 21 rows (including time)
        # so we make the font a bit smaller to make it more likely to view all the lines
        ret_string += "  tooltip: { textStyle: { fontSize: 12 } },\n"
        ret_string += "  legend: { textStyle: { fontSize: 12 } },\n"
        ret_string += '  explorer: { actions: ["dragToZoom", "rightClickToReset"], keepInBounds: true, maxZoomIn: 20.0 },\n'

        # HORIZONTAL AXIS
        ret_string += '  hAxis: { format: "%s", gridlines: { color: "lightgrey", count: 30 } },\n' % X_AXIS_DATEFORMAT

        # VERTICAL AXIS (OR AXES)
        if len(self.series_for_2nd_yaxis) > 0:
            # compute series that use 1st Y axis:
            num_series = self.data_table.getNumDataSeries()
            series_for_1st_yaxis = range(0, num_series)
            series_for_1st_yaxis = [item for item in series_for_1st_yaxis if item not in self.series_for_2nd_yaxis]
            # print("series_for_1st_yaxis: %s" % ','.join(str(x) for x in series_for_1st_yaxis))
            # print("self.series_for_2nd_yaxis: %s" % ','.join(str(x) for x in self.series_for_2nd_yaxis))

            # assign data series to the 2 Y axes:
            ret_string += "  series: {\n"
            ret_string += __internalWriteAxis(series_for_1st_yaxis, 0)
            ret_string += __internalWriteAxis(self.series_for_2nd_yaxis, 1)
            ret_string += "  },\n"

            # allocate 2 Y axes:
            assert len(self.y_axis_title) == 2
            ret_string += "  vAxes: {\n"
            ret_string += '    0: { title: "%s" },\n' % str(self.y_axis_title[0])
            ret_string += '    1: { title: "%s" }\n' % str(self.y_axis_title[1])
            ret_string += "  },\n"
        else:
            ret_string += '  vAxis: { title: "%s", gridlines: { color: "lightgrey", count: 11 } },\n' % str(self.y_axis_title)

        # graph stacking
        g_next_graph_need_stacking = self.stack_state
        if g_next_graph_need_stacking:
            ret_string += "  isStacked:  1\n"
            g_next_graph_need_stacking = 0
        else:
            ret_string += "  isStacked:  0\n"

        ret_string += "};\n"  # end of "options_%s" variable
        ret_string += "\n"
        ret_string += "if (g_chart && g_chart.clearChart)\n"
        ret_string += "  g_chart.clearChart();\n"
        ret_string += 'g_chart = new google.visualization.AreaChart(document.getElementById("chart_master_div"));\n'
        ret_string += "g_chart.draw(data_%s, options_%s);\n" % (
            self.js_name,
            self.js_name,
        )
        ret_string += "g_current_data = data_%s;\n" % (self.js_name)
        ret_string += "g_current_options = options_%s;\n" % (self.js_name)
        return ret_string

    def genGoogleChartJS_BubbleChart(self):
        assert len(self.y_axis_title) == 2
        ret_string = ""
        ret_string += "var options_%s = {\n" % (self.js_name)
        ret_string += '  explorer: { actions: ["dragToZoom", "rightClickToReset"], keepInBounds: true, maxZoomIn: 20.0 },\n'
        ret_string += '  chartArea: { left: "5%", width: "85%", top: "10%", height: "80%" },\n'
        ret_string += '  title: "%s",\n' % (self.graph_title)
        ret_string += '  hAxis: { title:"%s" },\n' % str(self.y_axis_title[0])
        ret_string += '  vAxis: { title:"%s" },\n' % str(self.y_axis_title[1])
        ret_string += "  sizeAxis: { maxSize: 200 },\n"
        ret_string += "  bubble: { textStyle: {fontSize: 15} }\n"
        ret_string += "};\n"  # end of "options_%s" variable
        ret_string += "\n"
        ret_string += "if (g_chart && g_chart.clearChart)\n"
        ret_string += "  g_chart.clearChart();\n"
        ret_string += 'g_chart = new google.visualization.BubbleChart(document.getElementById("chart_master_div"));\n'
        ret_string += "g_chart.draw(data_%s, options_%s);\n" % (
            self.js_name,
            self.js_name,
        )
        ret_string += "g_current_data = data_%s;\n" % (self.js_name)
        ret_string += "g_current_options = options_%s;\n" % (self.js_name)
        return ret_string

    def toGoogleChartJS(self):
        global g_next_graph_need_stacking

        # generate the JS
        js_code_inner = self.data_table.toGoogleChartTable(self.js_name)

        if self.graph_type == GRAPH_TYPE_AREA_CHART:
            js_code_inner += self.genGoogleChartJS_AreaChart()
        else:
            js_code_inner += self.genGoogleChartJS_BubbleChart()

        js_code = "function draw_%s() {\n" % (self.js_name)
        js_code += textwrap.indent(js_code_inner, " " * JS_INDENT_SIZE)

        # this graph will be activated by either
        #  - a button that should reset all comboboxes of the page
        #  - a combo box entry that should reset all other comboboxes in the page
        js_code += '  reset_combo_boxes("%s");\n' % self.combobox_label

        js_code += "}\n"  # end of draw_%s function
        js_code += "\n"

        return js_code


# =======================================================================================================
# HtmlOutputPage
# =======================================================================================================


class HtmlOutputPage:
    """
    This is able to produce a self-contained HTML page with embedded JavaScript to draw performance charts
    """

    def __init__(self, outfile, title):
        self.title = title
        self.outfile = outfile
        self.file = open(outfile, "w")  # Open the output file
        self.graphs = []

    def appendGoogleChart(self, chart):
        assert isinstance(chart, GoogleChartsGraph)
        self.graphs.append(chart)

    def startHtmlHead(self):
        """Write the head of the HTML webpage and start the JS section"""
        self.file.write(
            """<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>{pageTitle}</title>""".format(
                pageTitle=self.title
            )
        )

        self.file.write(
            """
  <style>
     html,body { height:85%; }
     body { background-color: #eaeaea; }
     h3 { margin: 0px; }
     ul { margin: 0 0 0 0;padding-left: 20px; }
     button { margin-bottom: 3px; }
     #monitored_system_span { background-color: white; color: red; padding: 4px; }
     #button_table { width:100%; border-collapse: collapse; }
     #button_table_col { border: darkgrey; border-style: solid; border-width: 2px; padding: 6px; margin: 6px; }
     #chart_master_div { width:98%; height:85%; border: darkgrey; border-style: solid; border-width: 2px; margin-left: auto; margin-right: auto}
     #chart_master_inner_div { position: absolute; top: 50%; left: 50%; -ms-transform: translate(-50%, -50%); transform: translate(-50%, -50%); }
     #chart_master_inner_p { font-size: x-large; }
     #bottom_div { float:left; max-width: 40%; border: darkgrey; border-style: solid; border-width: 2px; padding: 6px; margin: 6px; }
     #bottom_about_div { float:right; max-width: 15%; border: darkgrey; border-style: solid; border-width: 2px; padding: 6px; margin: 6px; }
     #bottom_div h3 { font-size: medium; }
     #bottom_div li { font-size: smaller; }
     #bottom_about_div h3 { font-size: medium; }
     #bottom_about_div li { font-size: smaller; }
     #bottom_table_val { font-family: monospace; }
  </style>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/pako@1.0.10/dist/pako.min.js"></script>
  <script type="text/javascript" src="https://www.gstatic.com/charts/loader.js"></script>
  <script type="text/javascript">
// Load the Visualization API and the corechart package; version 51 is June 2021 version
google.charts.load('51', {'packages':['corechart']});
google.setOnLoadCallback(setup_button_click_handlers);

/* The global chart object: */
var g_chart = null;

/* Currently selected data & options: */
var g_current_data = null;
var g_current_options = null;

/* The global window showing the configuration of all collected data: */
var g_configWindow = null;

/* Create a trigger for window resize that will redraw current chart */
var g_window_resize_timer = null;
window.addEventListener('resize', function(e){
  if (g_window_resize_timer) 
    clearTimeout(g_window_resize_timer);

  g_window_resize_timer = setTimeout(function() {
    if (g_current_data && g_current_options)
      g_chart.draw(g_current_data, g_current_options);
  }, 500);
});

/* Utility function used with combobox controls: */
function call_function_named(func_name) {
  eval(func_name + "()");
}

/* Utility function used to clear main graph: */
function clear_chart() {
  if (g_chart && g_chart.clearChart)
    g_chart.clearChart();
}

"""
        )
        # at this point we will generate all helper JS functions

    def endHtmlHead(self, config):
        """Finish the JS portion and HTML head tag"""

        # convert into JS all the charts that belong to this HTML document:
        combo_box_ctrls = set()
        for num, graph in enumerate(self.graphs, start=1):
            self.file.write(graph.toGoogleChartJS())
            if len(graph.combobox_label) > 0:
                combo_box_ctrls.add(graph.combobox_label)

        # add all event listeners for button clicks:
        self.file.write("function setup_button_click_handlers() {\n")
        for num, graph in enumerate(self.graphs, start=1):
            if len(graph.combobox_label) == 0:
                self.file.write('  document.getElementById("btn_draw_%s").addEventListener("click", draw_%s);\n' % (graph.js_name, graph.js_name))
            else:
                # this will be selected from a combobox, no need to hook into a button
                pass
        self.file.write('  document.getElementById("btn_show_config").addEventListener("click", show_config_window);\n')
        self.file.write("}\n")  # end of setup_button_click_handlers()

        # add function to reset all comboboxes
        self.file.write(
            """
/* Utility function used to reset combobox controls: */
function reset_combo_boxes(combobox_to_exclude_from_reset) {
"""
        )
        for num, comboname in enumerate(sorted(combo_box_ctrls), start=1):
            self.file.write('  if (combobox_to_exclude_from_reset != "%s")\n' % comboname)
            self.file.write('      document.getElementById("select_combobox_%s").value = "clear_chart";\n' % comboname)
        self.file.write("}\n")  # end of reset_combo_boxes()

        self.file.write(config)
        self.file.write("  </script>\n")
        self.file.write("</head>\n")

    def startHtmlBody(self, cgroupName, monitored_system):
        self.file.write("<body>\n")
        self.file.write('  <h1>Monitoring data collected from <span id="monitored_system_span">' + monitored_system + "</span></h1>\n")
        self.file.write('  <div id="button_div">\n')
        self.file.write('  <table id="button_table">\n')

        # Table header row
        self.file.write("  <tr>\n")
        self.file.write('    <td id="button_table_col"></td><td id="button_table_col"><b>CGroup</b> (Data collected from %s)</td>\n' % cgroupName)
        self.file.write('    <td id="button_table_col"><b>Baremetal</b> (Data collected from /proc)</td>\n')
        self.file.write("  </tr>\n")

        # Datarow
        self.file.write("  <tr>\n")
        self.file.write('  <td id="button_table_col">\n')
        self.file.write('    <button id="btn_show_config"><b>Configuration</b></button><br/>\n')
        self.file.write('  </td><td id="button_table_col">\n')

        def write_buttons_for_graph_type(source_data):
            nwritten_controls = 0

            # find all graphs that will be activated through a combobox
            graphs_combobox = {}
            for num, graph in enumerate(self.graphs, start=1):
                if graph.source_data == source_data and len(graph.combobox_label) > 0:
                    if graph.combobox_label not in graphs_combobox:
                        # add new dict entry as empty list
                        graphs_combobox[graph.combobox_label] = []

                    # add to the existing dict entry a new graph:
                    graphs_combobox[graph.combobox_label].append([graph.combobox_entry, graph.js_name])

            # generate the CPU select box:
            if len(graphs_combobox) > 0:
                for combobox_label in graphs_combobox.keys():
                    graph_list = graphs_combobox[combobox_label]
                    self.file.write('    <select id="select_combobox_%s" onchange="call_function_named(this.value)">\n' % (combobox_label))
                    self.file.write('      <option value="clear_chart">None</option>\n')
                    for entry in graph_list:
                        button_label = entry[0]
                        js_name = entry[1]
                        self.file.write('      <option value="draw_%s">%s</option>\n' % (js_name, button_label))
                    self.file.write("    </select>\n")
                    nwritten_controls += 1

            # find in all graphs registered so far all those related to the CGROUP
            for num, graph in enumerate(self.graphs, start=1):
                if graph.source_data == source_data:
                    if len(graph.combobox_label) > 0:
                        continue  # skip - already drawn via <select>
                    elif "CPU" in graph.button_label:
                        colour = "red"
                    elif graph.button_label.startswith("Memory"):
                        colour = "darkorange"
                    elif graph.button_label.startswith("Network"):
                        colour = "darkblue"
                    elif graph.button_label.startswith("Disk"):
                        colour = "darkgreen"
                    else:
                        colour = "black"
                    self.file.write(
                        '    <button id="btn_draw_' + graph.js_name + '" style="color:' + colour + '"><b>' + graph.button_label + "</b></button>\n"
                    )
                    nwritten_controls += 1

            if nwritten_controls == 0:
                self.file.write("N/A")

        write_buttons_for_graph_type(GRAPH_SOURCE_DATA_CGROUP)
        self.file.write('      </td><td id="button_table_col">\n')
        write_buttons_for_graph_type(GRAPH_SOURCE_DATA_BAREMETAL)

        self.file.write("  </td></tr>\n")
        self.file.write("  </table>\n")
        self.file.write("  </div>\n")
        self.file.write("  <p></p>\n")

        # finally generate the element where the main chart is going to be drawn:
        self.file.write(
            '  <div id="chart_master_div"><div id="chart_master_inner_div"><p id="chart_master_inner_p">...click on a button above to show a graph...</p></div></div>\n'
        )

    def appendHtmlTable(self, name, table_entries, div_id="bottom_div"):
        self.file.write("  <div id='" + div_id + "'>\n")
        self.file.write("    <h3>" + name + "</h3>\n")
        self.file.write("    <table>\n")
        self.file.write("    <tr><td><ul>\n")
        for i, entry in enumerate(table_entries, start=1):
            self.file.write("      <li>" + entry[0] + " <span id='bottom_table_val'>" + entry[1] + "</span></li>\n")
            if (i % 4) == 0:
                self.file.write("      </ul></td><td><ul>\n")
        self.file.write("    </ul></td></tr>\n")
        self.file.write("    </table>\n")
        self.file.write("  </div>\n")

    def endHtmlBody(self):
        self.file.write("</body>\n")
        self.file.write("</html>\n")
        self.file.close()


# =======================================================================================================
# CMonitorGraphGenerator
# =======================================================================================================


class CMonitorGraphGenerator:
    """
    This is the main class of cmonitor_chart, able to read a JSON file produced by cmonitor_collector,
    extract the most useful information and render them inside an HtmlOutputPage object.
    """

    def __init__(self, output_page, jheader, jdata):
        self.output_page = output_page  # must be of type HtmlOutputPage
        self.jheader = jheader  # a dictionary with cmonitor_collector "header" JSON object
        self.jdata = jdata  # a list of dictionaries with cmonitor_collector "samples" objects

        # in many places below we need to get "immutable" data that we know won't change across all samples
        # like the names of network devices or the list of CPUs...
        # since for some metrics the very sample does not contain any KPI (e.g. cgroup network traffic is generated
        # only for samples after the first one) if possible we pick the 2nd sample and not the 1st one:
        assert len(self.jdata) >= 2
        self.sample_template = self.jdata[1]

        # detect num of CPUs:
        self.baremetal_logical_cpus_indexes = []
        if "stat" in self.sample_template:
            self.baremetal_logical_cpus_indexes = CMonitorGraphGenerator.collect_logical_cpu_indexes_from_section(self.sample_template, "stat")
            if verbose:
                print(
                    "Found %d CPUs in baremetal stats with logical indexes [%s]"
                    % (
                        len(self.baremetal_logical_cpus_indexes),
                        ", ".join(str(x) for x in self.baremetal_logical_cpus_indexes),
                    )
                )

        self.cgroup_logical_cpus_indexes = []
        if "cgroup_cpuacct_stats" in self.sample_template:
            self.cgroup_logical_cpus_indexes = CMonitorGraphGenerator.collect_logical_cpu_indexes_from_section(
                self.sample_template, "cgroup_cpuacct_stats"
            )
            if verbose:
                print(
                    "Found %d CPUs in cgroup stats with logical indexes [%s]"
                    % (
                        len(self.cgroup_logical_cpus_indexes),
                        ", ".join(str(x) for x in self.cgroup_logical_cpus_indexes),
                    )
                )

    # =======================================================================================================
    # Private helpers
    # =======================================================================================================

    @staticmethod
    def collect_logical_cpu_indexes_from_section(jsample, section_name):
        """
        Walks over given JSON sample looking for keys 'cpuXYZ' and storing all 'XYZ' CPU indexes.
        Returns a list of CPU indexes
        """
        logical_cpus_indexes = []
        for key in jsample[section_name]:
            if key.startswith("cpu") and key != "cpu_total" and key != "cpu_tot":
                cpuIdx = int(key[3:])
                logical_cpus_indexes.append(cpuIdx)
                # print("%s %s" %(key, cpuIdx))
        return logical_cpus_indexes

    def __choose_byte_divider(self, mem_total_bytes):
        divider = 1
        unit = "Bytes"
        if mem_total_bytes > 9e9:
            divider = 1e9
            unit = "GB"
        elif mem_total_bytes > 9e6:
            divider = 1e6
            unit = "MB"
        # print("%d -> %s, %d" % (mem_total_bytes,unit, divider))
        return (divider, unit)

    def __print_data_loading_stats(self, desc, n_invalid_samples):
        if n_invalid_samples > 0:
            print(
                "While parsing %s statistics found %d/%d (%.1f%%) samples that did not contain some required JSON section."
                % (
                    desc,
                    n_invalid_samples,
                    len(jdata),
                    100 * n_invalid_samples / len(jdata),
                )
            )
        else:
            print("Parsed correctly %d samples for [%s] category" % (len(self.jdata), desc))

    def __cgroup_get_cpu_quota_percentage(self):
        cpu_quota_perc = 100
        if "cpu_quota_perc" in self.jheader["cgroup_config"]:
            cpu_quota_perc = 100 * self.jheader["cgroup_config"]["cpu_quota_perc"]
            if cpu_quota_perc == -100:  # means there's no CPU limit
                cpu_quota_perc = -1
        return cpu_quota_perc

    @staticmethod
    def cgroup_get_cpu_throttling(s):
        cpu_throttling = 0
        if "throttling" in s["cgroup_cpuacct_stats"]:
            # throttling is new since cmonitor_collector 1.5-0
            nr_periods = s["cgroup_cpuacct_stats"]["throttling"]["nr_periods"]
            if nr_periods:
                cpu_throttling = 100 * s["cgroup_cpuacct_stats"]["throttling"]["nr_throttled"] / nr_periods
        return cpu_throttling

    def __cgroup_get_memory_limit(self):
        if "memory_limit_bytes" in self.jheader["cgroup_config"]:
            # IMPORTANT: this value could be -1 if there's no limit
            cgroup_limit_bytes = self.jheader["cgroup_config"]["memory_limit_bytes"]

        if self.jheader["cgroup_config"]["version"] == 1:
            # cgroups v1
            system_total_bytes = self.sample_template["cgroup_memory_stats"]["stat.cache"] + self.sample_template["cgroup_memory_stats"]["stat.rss"]
        else:
            # cgroups v2
            if "proc_meminfo" in self.jheader:
                system_total_bytes = self.jheader["proc_meminfo"]["MemTotal"]
            else:
                # we have no clue what will be the "max memory" to plot (unless we do full scanning of all samples,
                # which of course is very slow)... so we assume that twice of memory used by first sample will be
                # a good approx:
                system_total_bytes = self.sample_template["cgroup_memory_stats"]["stat.current"] * 2

        if cgroup_limit_bytes == -1:
            divider, unit = self.__choose_byte_divider(system_total_bytes)
        else:
            divider, unit = self.__choose_byte_divider(cgroup_limit_bytes)
        return cgroup_limit_bytes, divider, unit

    # =======================================================================================================
    # Public API
    # =======================================================================================================

    def generate_config_viewer(self):
        """
        Creates into output document a snippet of Javascript code to open a new HTML window with
        a basic rendering of cmonitor_collector configuration and the monitored server.
        """

        # ----- add config box
        def configdump(section, displayName):
            # newstr = '<h3>' + displayName + '</h3>\\\n'
            newstr = "<tr><td colspan='2' id='sectioncol'>" + displayName + "</td></tr>\\\n"
            config_dict = self.jheader[section]
            for label in config_dict:
                newstr += "    <tr>\\\n"
                newstr += "    <td id='configkey'>%s</td><td id='configval'>%s</td>\\\n" % (
                    label.capitalize().replace("_", " "),
                    str(config_dict[label]),
                )
                newstr += "    </tr>\\\n"
            return newstr

        def sizeof_fmt(num, suffix="B"):
            for unit in ["", "Ki", "Mi", "Gi", "Ti", "Pi", "Ei", "Zi"]:
                if abs(num) < 1024.0:
                    return "%3.1f%s%s" % (num, unit, suffix)
                num /= 1024.0
            return "%.1f%s%s" % (num, "Yi", suffix)

        # provide some human-readable config files:
        if "cgroup_config" in self.jheader:
            avail_cpus = self.jheader["cgroup_config"]["cpus"].split(",")
            self.jheader["cgroup_config"]["num_allowed_cpus"] = len(avail_cpus)
            self.jheader["cgroup_config"]["memory_limit_bytes"] = sizeof_fmt(int(self.jheader["cgroup_config"]["memory_limit_bytes"]))
            self.jheader["cgroup_config"]["cpus"] = self.jheader["cgroup_config"]["cpus"].replace(",", ", ")

        if "cmonitor" in self.jheader:
            if self.jheader["cmonitor"]["sample_num"] == 0:
                self.jheader["cmonitor"]["sample_num"] = "Infinite"

        if "proc_meminfo" in self.jheader:
            self.jheader["proc_meminfo"]["MemTotal"] = sizeof_fmt(int(self.jheader["proc_meminfo"]["MemTotal"]))
            self.jheader["proc_meminfo"]["Hugepagesize"] = sizeof_fmt(int(self.jheader["proc_meminfo"]["Hugepagesize"]))

        config_str = ""
        config_str += "\nfunction show_config_window() {\n"
        config_str += "    if (g_configWindow) g_configWindow.close();\n"
        config_str += '    g_configWindow = window.open("", "MsgWindow", "width=1024, height=800, toolbar=no");\n'
        config_str += '    g_configWindow.document.write("\\\n'
        config_str += "    <html><head>\\\n"
        config_str += "      <title>Configuration</title>\\\n"
        config_str += "      <style>\\\n"
        config_str += "        table { padding-left: 2ex; }\\\n"
        config_str += "        #sectioncol {font-weight: bold; padding: 1ex; font-size: large;background-color: lightsteelblue;}\\\n"
        config_str += "        #configkey {font-weight: bold;}\\\n"
        config_str += "        #configval {font-family: monospace;}\\\n"
        config_str += "      </style>\\\n"
        config_str += "    </head><body>\\\n"
        config_str += "      <h2>Monitored System Summary</h2>\\\n"
        config_str += "      <table>\\\n"
        config_str += configdump("identity", "Server Identity")
        config_str += configdump("os_release", "Operating System Release")
        config_str += configdump("proc_version", "Linux Kernel Version")
        if "cgroup_config" in self.jheader:  # if cgroups are off, this section will not be present
            config_str += configdump("cgroup_config", "Linux Control Group (CGroup) Configuration")
        if "lscpu" in self.jheader:  # Alpine docker has no lscpu utility
            config_str += configdump("lscpu", "CPU Overview")
        if "proc_meminfo" in self.jheader:
            config_str += configdump("proc_meminfo", "Memory Overview")
        # config_str += configdump("cpuinfo", "CPU Core Details")
        config_str += "      </table>\\\n"
        config_str += "      <h2>Monitoring Summary</h2>\\\n"
        config_str += "      <table>\\\n"
        config_str += configdump("cmonitor", "Performance Stats Collector Configuration")
        config_str += "      </table>\\\n"
        config_str += "    </body></html>\\\n"
        config_str += '");\n}\n\n'

        self.output_page.endHtmlHead(config_str)

    def generate_cgroup_topN_procs(self, numProcsToShow=20, thread_filter=""):
        # if process data was not collected, just return:
        if "cgroup_tasks" not in self.sample_template:
            return

        # build a dictionary containing cumulative metrics for CPU/IO/MEM data for each process
        # along all collected samples
        process_dict = {}
        max_mem_bytes = 0
        max_io_bytes = 0
        n_invalid_samples = 0
        for sample in self.jdata:
            try:
                for process in sample["cgroup_tasks"]:
                    # parse data from JSON
                    entry = sample["cgroup_tasks"][process]
                    cmd = entry["cmd"]
                    # filter by thread name if there is a filter
                    if thread_filter and thread_filter not in cmd:
                        continue
                    cputime = entry["cpu_usr_total_secs"] + entry["cpu_sys_total_secs"]
                    iobytes = entry["io_total_read"] + entry["io_total_write"]
                    membytes = entry["mem_rss_bytes"]  # take RSS, more realistic/useful compared to the "mem_virtual_bytes"
                    thepid = entry["pid"]

                    # keep track of maxs:
                    max_mem_bytes = max(membytes, max_mem_bytes)
                    max_io_bytes = max(iobytes, max_io_bytes)

                    try:  # update the current entry
                        process_dict[thepid]["cpu"] = cputime
                        process_dict[thepid]["io"] = iobytes
                        process_dict[thepid]["mem"] = membytes
                        process_dict[thepid]["cmd"] = cmd
                    except:  # no current entry so add one
                        process_dict.update(
                            {
                                thepid: {
                                    "cpu": cputime,
                                    "io": iobytes,
                                    "mem": membytes,
                                    "cmd": cmd,
                                }
                            }
                        )
            except KeyError as e:  # avoid crashing if a key is not present in the dictionary...
                print(f"Missing cgroup data while parsing {i}-th sample: {e}")
                n_invalid_samples += 1
                pass

        self.__print_data_loading_stats("per-process", n_invalid_samples)

        # now sort all collected processes by the amount of CPU*memory used:
        # NOTE: sorted() will return just the sorted list of KEYs = PIDs
        def sort_key(d):
            # return process_dict[d]['cpu'] * process_dict[d]['mem']
            return process_dict[d]["cpu"]

        topN_process_pids_list = sorted(process_dict, key=sort_key, reverse=True)

        # truncate to first N:
        if numProcsToShow > 0:
            topN_process_pids_list = topN_process_pids_list[0:numProcsToShow]

        mem_divider, mem_unit = self.__choose_byte_divider(max_mem_bytes)
        io_divider, io_unit = self.__choose_byte_divider(max_io_bytes)

        def get_nice_cmd(pid):
            return "%s (%d)" % (process_dict[pid]["cmd"], pid)

        # now select the N top processes and put their data in a GoogleChart table:
        topN_process_table = GoogleChartsGenericTable(["Command", "CPU time", "I/O " + io_unit, "Command", "Memory " + mem_unit])
        for i, pid in enumerate(topN_process_pids_list):
            p = process_dict[pid]
            nicecmd = get_nice_cmd(pid)

            if verbose:
                print("Processing data for %d-th CPU-top-scorer process [%s]" % (i + 1, nicecmd))
            topN_process_table.addRow([p["cmd"], p["cpu"], p["io"] / io_divider, nicecmd, p["mem"] / mem_divider])

        # did we collect processes or threads?
        string_collected_kpis = self.jheader["cmonitor"]["collecting"]  # e.g. "cgroup_cpu,cgroup_memory,cgroup_threads"
        collected_threads = "cgroup_threads" in string_collected_kpis
        if collected_threads:
            chart_desc_prefix = "Top %d threads " % numProcsToShow
            if verbose:
                print("Threads (instead of processes) have been collected in the input JSON file.")
        else:
            chart_desc_prefix = "Top %d processes " % numProcsToShow

        # generate the bubble chart graph:
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                button_label="CPU/Memory/Disk Bubbles",
                graph_source=GRAPH_SOURCE_DATA_CGROUP,
                graph_type=GRAPH_TYPE_BUBBLE_CHART,
                graph_title=chart_desc_prefix + "for CPU/disk total usage on X/Y axes; memory usage as bubble size (from cgroup stats)",
                y_axis_title=["CPU time", "I/O " + io_unit],
                data=topN_process_table,
            )
        )

        # now that first pass is done, adjust units for memory
        mem_limit_bytes, mem_divider, mem_unit = self.__cgroup_get_memory_limit()

        # now generate instead a table of CPU/IO/MEMORY usage over time per process:
        process_table = {}
        process_table["cpu"] = GoogleChartsTimeSeries(
            ["Timestamp", "Limit/Quota", "Throttling"] + [get_nice_cmd(pid) for pid in topN_process_pids_list]
        )
        process_table["io"] = GoogleChartsTimeSeries(["Timestamp"] + [get_nice_cmd(pid) for pid in topN_process_pids_list])
        process_table["mem"] = GoogleChartsTimeSeries(
            ["Timestamp", "Limit", "Alloc Failures"] + [get_nice_cmd(pid) for pid in topN_process_pids_list]
        )

        cpu_quota_perc = self.__cgroup_get_cpu_quota_percentage()
        for sample in self.jdata:
            try:
                row = {}
                for key in ["cpu", "io", "mem"]:
                    row[key] = [sample["timestamp"]["UTC"]]

                # CPU graph has
                # - limit/quota and
                # - throttling
                # as additional columns right after the timestamp
                row["cpu"].append(cpu_quota_perc)
                row["cpu"].append(CMonitorGraphGenerator.cgroup_get_cpu_throttling(sample))

                # Memory graph has
                # - limit
                # - alloc failures
                # as additional columns right after the timestamp
                row["mem"].append(mem_limit_bytes / mem_divider)
                row["mem"].append(sample["cgroup_memory_stats"]["failcnt"])

                for top_process_pid in topN_process_pids_list:
                    # print(top_process_pid)
                    json_key = "pid_%s" % top_process_pid
                    if json_key in sample["cgroup_tasks"]:
                        top_proc_sample = sample["cgroup_tasks"][json_key]
                        row["cpu"].append(top_proc_sample["cpu_tot"])
                        row["io"].append(top_proc_sample["io_rchar"] + top_proc_sample["io_wchar"])
                        row["mem"].append(top_proc_sample["mem_rss_bytes"] / mem_divider)

                        # keep track of maxs:
                        max_mem_bytes = max(membytes, max_mem_bytes)
                        max_io_bytes = max(iobytes, max_io_bytes)
                    else:
                        # probably this process was born later or dead earlier than this timestamp
                        row["cpu"].append(0)
                        row["io"].append(0)
                        row["mem"].append(0)

                for key in ["cpu", "io", "mem"]:
                    process_table[key].addRow(row[key])
            except KeyError:  # avoid crashing if a key is not present in the dictionary...
                # print("Missing cgroup data while parsing sample %d" % i)
                pass

        # produce the 3 graphs "by process":
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                data=process_table["cpu"],
                graph_title=chart_desc_prefix + "for CPU usage (from cgroup stats)",
                button_label="CPU by Thread" if collected_threads else "CPU by Process",
                y_axis_title="CPU (%)",
                graph_source=GRAPH_SOURCE_DATA_CGROUP,
                stack_state=False,
            )
        )
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                data=process_table["io"],
                graph_title=chart_desc_prefix + "for I/O usage (from cgroup stats)",
                button_label="IO by Thread" if collected_threads else "IO by Process",
                y_axis_title="IO Read+Write (Bytes Per Sec)",
                graph_source=GRAPH_SOURCE_DATA_CGROUP,
                stack_state=False,
            )
        )
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                data=process_table["mem"],
                graph_title=chart_desc_prefix + "for memory usage (from cgroup stats)",
                button_label="Memory by Thread" if collected_threads else "Memory by Process",
                y_axis_title="RSS Memory (%s)" % mem_unit,
                graph_source=GRAPH_SOURCE_DATA_CGROUP,
                stack_state=False,
            )
        )

    def generate_baremetal_disks_io(self):
        # if disk data was not collected, just return:
        if "disks" not in self.sample_template:
            return

        all_disks = self.sample_template["disks"].keys()
        if len(all_disks) == 0:
            return

        # see https://www.kernel.org/doc/Documentation/iostats.txt

        diskcols = ["Timestamp"]
        for device in all_disks:
            # diskcols.append(str(device) + " Disk Time")
            # diskcols.append(str(device) + " Reads")
            # diskcols.append(str(device) + " Writes")
            diskcols.append(str(device) + " Read MB")
            diskcols.append(str(device) + " Write MB")

        # convert from kB to MB
        divider = 1000

        #
        # MAIN LOOP
        # Process JSON sample and fill the GoogleChartsTimeSeries() object
        #

        disk_table = GoogleChartsTimeSeries(diskcols)
        for i, s in enumerate(self.jdata):
            if i == 0:
                continue

            row = []
            row.append(s["timestamp"]["UTC"])
            for device in all_disks:
                # row.append(s["disks"][device]["time"])
                # row.append(s["disks"][device]["reads"])
                # row.append(s["disks"][device]["writes"])
                row.append(s["disks"][device]["rkb"] / divider)
                row.append(-s["disks"][device]["wkb"] / divider)
            disk_table.addRow(row)

        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                button_label="Disk I/O",
                graph_source=GRAPH_SOURCE_DATA_BAREMETAL,
                graph_title="Disk I/O (from baremetal stats)",
                y_axis_title="MB",
                data=disk_table,
            )
        )
        return

    # def generate_filesystems(self.output_page, self.jdata):
    #     global self.graphs
    #     fsstr = ""
    #     for fs in self.sample_template["filesystems"].keys():
    #         fsstr = fsstr + "'" + fs + "',"
    #     fsstr = fsstr[:-1]
    #     startHtmlHead_line_graph(self.output_page, fsstr)
    #     for i, s in enumerate(self.jdata):
    #         self.output_page.write(",['Date(%s)' " % (googledate(s['timestamp']["UTC"])))
    #         for fs in s["filesystems"].keys():
    #             self.output_page.write(", %.1f" % (s["filesystems"][fs]["fs_full_percent"]))
    #         self.output_page.write("]\n")
    #     self.output_page.appendGoogleChart(GoogleChartsGraph( 'File Systems Used percent')
    #     return

    def __generate_network_traffic_graphs(self, graph_source, sample_section_name, graph_desc):
        # if network traffic data was not collected, just return:
        if sample_section_name not in self.sample_template:
            return

        all_netdevices = self.sample_template[sample_section_name].keys()
        if len(all_netdevices) == 0:
            return

        netcols = ["Timestamp"]
        for device in all_netdevices:
            netcols.append(str(device) + "+in")
            netcols.append(str(device) + "-out")

        # convert from bytes to MB
        divider = 1000 * 1000

        #
        # MAIN LOOP
        # Process JSON sample and fill the GoogleChartsTimeSeries() object
        #

        # MB/sec

        net_table = GoogleChartsTimeSeries(netcols)
        for i, s in enumerate(self.jdata):
            if i == 0:
                continue

            row = [s["timestamp"]["UTC"]]
            for device in all_netdevices:
                try:
                    row.append(+s[sample_section_name][device]["ibytes"] / divider)
                    row.append(-s[sample_section_name][device]["obytes"] / divider)
                except KeyError:
                    if verbose:
                        print("Missing key '%s' while parsing sample %d" % (device, i))
                    row.append(0)
                    row.append(0)
            net_table.addRow(row)

        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                graph_title=f"Network Traffic in MB/s {graph_desc}",
                button_label="Network Traffic (MB/s)",
                y_axis_title="MB/s",
                graph_source=graph_source,
                stack_state=False,
                data=net_table,
            )
        )

        # PPS

        net_table = GoogleChartsTimeSeries(netcols)
        for i, s in enumerate(self.jdata):
            if i == 0:
                continue

            row = [s["timestamp"]["UTC"]]
            for device in all_netdevices:
                try:
                    row.append(+s[sample_section_name][device]["ipackets"])
                    row.append(-s[sample_section_name][device]["opackets"])
                except KeyError:
                    if verbose:
                        print("Missing key '%s' while parsing sample %d" % (device, i))
                    row.append(0)
                    row.append(0)
            net_table.addRow(row)

        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                graph_title=f"Network Traffic in PPS {graph_desc}",
                button_label="Network Traffic (PPS)",
                y_axis_title="PPS",
                graph_source=graph_source,
                stack_state=False,
                data=net_table,
            )
        )
        return

    def generate_baremetal_network_traffic(self):
        self.__generate_network_traffic_graphs(GRAPH_SOURCE_DATA_BAREMETAL, "network_interfaces", "(from baremetal stats)")

    def generate_cgroup_network_traffic(self):
        self.__generate_network_traffic_graphs(GRAPH_SOURCE_DATA_CGROUP, "cgroup_network", "(from cgroup stats)")

    def generate_baremetal_cpus(self):
        # if baremetal CPU data was not collected, just return:
        if "stat" not in self.sample_template:
            return

        # prepare empty tables
        baremetal_cpu_stats = {}
        for c in self.baremetal_logical_cpus_indexes:
            baremetal_cpu_stats[c] = GoogleChartsTimeSeries(
                [
                    "Timestamp",
                    "User",
                    "Nice",
                    "System",
                    "Idle",
                    "I/O wait",
                    "Hard IRQ",
                    "Soft IRQ",
                    "Steal",
                ]
            )

        all_cpus_table = GoogleChartsTimeSeries(["Timestamp"] + [("CPU" + str(x)) for x in self.baremetal_logical_cpus_indexes])

        #
        # MAIN LOOP
        # Process JSON sample and fill the GoogleChartsTimeSeries() object
        #

        for i, s in enumerate(self.jdata):
            if i == 0:
                continue  # skip first sample

            ts = s["timestamp"]["UTC"]
            all_cpus_row = [ts]
            for c in self.baremetal_logical_cpus_indexes:
                cpu_stats = s["stat"]["cpu" + str(c)]
                cpu_total = (
                    cpu_stats["user"]
                    + cpu_stats["nice"]
                    + cpu_stats["sys"]
                    + cpu_stats["iowait"]
                    + cpu_stats["hardirq"]
                    + cpu_stats["softirq"]
                    + cpu_stats["steal"]
                )
                baremetal_cpu_stats[c].addRow(
                    [
                        ts,
                        cpu_stats["user"],
                        cpu_stats["nice"],
                        cpu_stats["sys"],
                        cpu_stats["idle"],
                        cpu_stats["iowait"],
                        cpu_stats["hardirq"],
                        cpu_stats["softirq"],
                        cpu_stats["steal"],
                    ]
                )
                all_cpus_row.append(cpu_total)

            all_cpus_table.addRow(all_cpus_row)

        # Produce the javascript:
        for c in self.baremetal_logical_cpus_indexes:
            self.output_page.appendGoogleChart(
                GoogleChartsGraph(
                    data=baremetal_cpu_stats[c],  # Data
                    graph_title="Logical CPU " + str(c) + " (from baremetal stats)",
                    combobox_label="baremetal_cpus",
                    combobox_entry="CPU" + str(c),
                    y_axis_title="Time (%)",
                    graph_source=GRAPH_SOURCE_DATA_BAREMETAL,
                    stack_state=True,
                )
            )

        # Also produce the "all CPUs" graph
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                data=all_cpus_table,  # Data
                graph_title="All logical CPUs (from baremetal stats)",
                button_label="All CPUs",
                y_axis_title="Time (%)",
                graph_source=GRAPH_SOURCE_DATA_BAREMETAL,
                stack_state=False,
            )
        )
        return

    def generate_cgroup_cpus(self):
        if "cgroup_cpuacct_stats" not in self.sample_template:
            return  # cgroup mode not enabled at collection time!

        # prepare empty tables
        cpu_stats_table = {}
        for c in self.cgroup_logical_cpus_indexes:
            cpu_stats_table[c] = GoogleChartsTimeSeries(["Timestamp", "User", "System"])

        all_cpus_table = GoogleChartsTimeSeries(
            ["Timestamp", "Limit/Quota", "Throttling"] + [("CPU" + str(x)) for x in self.cgroup_logical_cpus_indexes]
        )

        #
        # MAIN LOOP
        # Process JSON sample and fill the GoogleChartsTimeSeries() object
        #

        cpu_quota_perc = self.__cgroup_get_cpu_quota_percentage()
        n_invalid_samples = 0
        for i, s in enumerate(self.jdata):
            if i == 0:
                continue  # skip first sample

            try:
                ts = s["timestamp"]["UTC"]

                all_cpus_row = [ts, cpu_quota_perc, CMonitorGraphGenerator.cgroup_get_cpu_throttling(s)]
                for c in self.cgroup_logical_cpus_indexes:
                    # get data:
                    cpu_stats = s["cgroup_cpuacct_stats"]["cpu" + str(c)]
                    if "sys" in cpu_stats:
                        cpu_sys = cpu_stats["sys"]
                    else:
                        cpu_sys = 0
                    cpu_total = cpu_stats["user"] + cpu_sys

                    # append data:
                    cpu_stats_table[c].addRow([ts, cpu_stats["user"], cpu_sys])
                    all_cpus_row.append(cpu_total)

                all_cpus_table.addRow(all_cpus_row)
            except KeyError:  # avoid crashing if a key is not present in the dictionary...
                # print("Missing cgroup data while parsing sample %d" % i)
                n_invalid_samples += 1
                pass

        self.__print_data_loading_stats("cgroup CPU", n_invalid_samples)

        # Produce 1 graph for each CPU:
        for c in self.cgroup_logical_cpus_indexes:
            self.output_page.appendGoogleChart(
                GoogleChartsGraph(
                    data=cpu_stats_table[c],  # Data
                    graph_title="Logical CPU " + str(c) + " (from CGroup stats)",
                    combobox_label="cgroup_cpus",
                    combobox_entry="CPU" + str(c),
                    y_axis_title="Time (%)",
                    graph_source=GRAPH_SOURCE_DATA_CGROUP,
                    stack_state=True,
                )
            )

        ver = int(self.jheader["cgroup_config"]["version"])

        # Also produce the "all CPUs" graph that includes some very useful KPIs like
        # - CPU limit imposed on Linux CFS scheduler
        # - Amount of CPU throttling
        # NOTE: when cgroups v2 are used, there's no per-CPU stat just the total CPU usage,
        #       so we change the title of the tab to reflect that
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                data=all_cpus_table,  # Data
                graph_title="All logical CPUs available in the cgroup" if ver == 1 else "CPU usage measured in the cgroup",
                button_label="All CPUs" if ver == 1 else "CPU",
                y_axis_title="Time (%)",
                graph_source=GRAPH_SOURCE_DATA_CGROUP,
                stack_state=False,
            )
        )

        return

    def generate_baremetal_memory(self):
        # if baremetal memory data was not collected, just return:
        if "proc_meminfo" not in self.sample_template:
            return

        #
        # MAIN LOOP
        # Process JSON sample and build Google Chart-compatible Javascript variable
        # See https://developers.google.com/chart/interactive/docs/reference
        #

        mem_total_bytes = self.sample_template["proc_meminfo"]["MemTotal"]
        baremetal_memory_stats = GoogleChartsTimeSeries(["Timestamp", "Used", "Cached (DiskRead)", "Free"])
        divider, unit = self.__choose_byte_divider(mem_total_bytes)

        for i, s in enumerate(self.jdata):
            if i == 0:
                continue  # skip first sample
            meminfo_stats = s["proc_meminfo"]

            if meminfo_stats["MemTotal"] != mem_total_bytes:
                continue  # this is impossible AFAIK (hot swap of memory is not handled!!)

            #
            # NOTE: most tools like e.g. free -k just map:
            #
            #   free output |   corresponding /proc/meminfo fields
            # --------------+---------------------------------------
            #   Mem: total  |   MemTotal
            #   Mem: used   |   MemTotal - MemFree - Buffers - Cached - Slab
            #   Mem: free   |   MemFree             ^^^^^^^^^           ^^^^
            #                                        Buffers and Slab are close to zero 99% of the time
            #
            # see https://access.redhat.com/solutions/406773

            mf = meminfo_stats["MemFree"]
            mc = meminfo_stats["Cached"]

            baremetal_memory_stats.addRow(
                [
                    s["timestamp"]["UTC"],
                    int((mem_total_bytes - mf - mc) / divider),  # compute used memory
                    int(mc / divider),  # cached
                    int(mf / divider),  # free
                ]
            )

        # Produce the javascript:
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                data=baremetal_memory_stats,  # Data
                graph_title="Memory usage in " + unit + " (from baremetal stats)",
                button_label="Memory",
                y_axis_title=unit,
                graph_source=GRAPH_SOURCE_DATA_BAREMETAL,
                stack_state=True,
            )
        )
        return

    def generate_cgroup_memory(self):
        # if cgroup data was not collected, just return:
        if "cgroup_memory_stats" not in self.sample_template:
            return

        #
        # MAIN LOOP
        # Process JSON sample and build Google Chart-compatible Javascript variable
        # See https://developers.google.com/chart/interactive/docs/reference
        #

        cgroup_memory_stats = GoogleChartsTimeSeries(["Timestamp", "Used", "Cached (DiskRead)", "Alloc Failures", "Limit"])

        ver = int(self.jheader["cgroup_config"]["version"])

        mem_limit_bytes, divider, unit = self.__cgroup_get_memory_limit()

        n_invalid_samples = 0
        for i, s in enumerate(self.jdata):
            if i == 0:
                continue  # skip first sample

            try:
                if ver == 1:
                    mu = s["cgroup_memory_stats"]["stat.rss"]
                    mc = s["cgroup_memory_stats"]["stat.cache"]
                    mfail = s["cgroup_memory_stats"]["failcnt"]
                else:
                    # cgroups v2
                    mu = s["cgroup_memory_stats"]["stat.anon"]
                    mc = s["cgroup_memory_stats"]["stat.file"]
                    mfail = s["cgroup_memory_stats"]["events.oom_kill"]
                cgroup_memory_stats.addRow(
                    [
                        s["timestamp"]["UTC"],
                        mu / divider,
                        mc / divider,
                        mfail,
                        mem_limit_bytes / divider,  # imposed limit of memory in this cgroup
                    ]
                )
            except KeyError as e:  # avoid crashing if a key is not present in the dictionary...
                print(f"Missing cgroup data while parsing {i}-th sample: {e}")
                n_invalid_samples += 1
                pass

        self.__print_data_loading_stats("cgroup memory", n_invalid_samples)

        # Produce the javascript:
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                data=cgroup_memory_stats,  # Data
                graph_title="Used memory in " + unit + " (from memory cgroup)",
                button_label="Memory",
                y_axis_title=[unit, "Alloc Failures"],
                graph_source=GRAPH_SOURCE_DATA_CGROUP,
                stack_state=False,
                series_for_2nd_yaxis=[2],
            )
        )  # put "failcnt" on 2nd y axis

        return

    def generate_baremetal_avg_load(self):
        #
        # MAIN LOOP
        # Process JSON sample and build Google Chart-compatible Javascript variable
        # See https://developers.google.com/chart/interactive/docs/reference
        #

        num_baremetal_cpus = 1
        if "lscpu" in self.jheader:
            num_baremetal_cpus = int(self.jheader["lscpu"]["cpus"])

        load_avg_stats = GoogleChartsTimeSeries(["Timestamp", "LoadAvg (1min)", "LoadAvg (5min)", "LoadAvg (15min)"])
        for i, s in enumerate(self.jdata):
            if i == 0:
                continue  # skip first sample

            #
            # See https://linux.die.net/man/5/proc
            # and https://blog.appsignal.com/2018/03/28/understanding-system-load-and-load-averages.html
            #
            # "The load of a system is essentially the number of processes active at any given time.
            #  When idle, the load is 0. When a process starts, the load is incremented by 1.
            #  A terminating process decrements the load by 1. Besides running processes,
            #  any process that's queued up is also counted. So, when one process is actively using the CPU,
            #  and two are waiting their turn, the load is 3."
            #  ...
            # "Generally, single-core CPU can handle one process at a time. An average load of 1.0 would mean
            #  that one core is busy 100% of the time. If the load average drops to 0.5, the CPU has been idle
            #  for 50% of the time."

            # since kernel reports a percentage in range [0-n], where n= number of cores,
            # we remap that in range [0-100%]

            load_avg_stats.addRow(
                [
                    s["timestamp"]["UTC"],
                    100 * float(s["proc_loadavg"]["load_avg_1min"]) / num_baremetal_cpus,
                    100 * float(s["proc_loadavg"]["load_avg_5min"]) / num_baremetal_cpus,
                    100 * float(s["proc_loadavg"]["load_avg_15min"]) / num_baremetal_cpus,
                ]
            )

        # Produce the javascript:
        self.output_page.appendGoogleChart(
            GoogleChartsGraph(
                data=load_avg_stats,  # Data
                graph_title="Average Load " + " (from baremetal stats)",
                button_label="Average Load",
                y_axis_title="Load (%)",
                graph_source=GRAPH_SOURCE_DATA_BAREMETAL,
                stack_state=False,
            )
        )
        return

    def generate_monitoring_summary(self):
        monitoring_summary = [
            # ( "User:", self.jheader["cmonitor"]["username"] ),   # not really useful
            ("Collected:", self.jheader["cmonitor"]["collecting"].replace(",", ", ")),
            # ( "Started sampling at:", self.sample_template["timestamp"]["datetime"] + " (Local)" ),   # not really useful
            ("Started sampling at:", self.jdata[0]["timestamp"]["UTC"] + " (UTC)"),
            ("Samples:", str(len(self.jdata))),
            ("Sampling Interval (s):", str(self.jheader["cmonitor"]["sample_interval_seconds"])),
            (
                "Total time sampled (hh:mm:ss):",
                str(datetime.timedelta(seconds=self.jheader["cmonitor"]["sample_interval_seconds"] * len(self.jdata))),
            ),
            ("Version (cmonitor_collector):", self.jheader["cmonitor"]["version"]),
            ("Version (cmonitor_chart):", VERSION_STRING),
        ]
        self.output_page.appendHtmlTable("Monitoring Summary", monitoring_summary)

    def __generate_monitored_summary_with_cpus(self, logical_cpus_indexes):
        # NOTE: unfortunately some useful information like:
        #        - RAM memory model/speed
        #        - Disk model/speed
        #        - NIC model/speed
        #       will not be available from inside a container, which is where cmonitor_collector usually runs...
        #       so we mostly show CPU stats:
        all_disks = []
        if "disks" in self.sample_template:
            all_disks = self.sample_template["disks"].keys()
        all_netdevices = []
        if "network_interfaces" in self.sample_template:
            all_netdevices = self.sample_template["network_interfaces"].keys()

        cpu_model = "Unknown"
        bogomips = "Unknown"
        if "lscpu" in self.jheader:
            cpu_model = self.jheader["lscpu"]["model_name"]
            bogomips = self.jheader["lscpu"]["bogomips"]

        monitored_summary = [
            ("Hostname:", self.jheader["identity"]["hostname"]),
            ("OS:", self.jheader["os_release"]["pretty_name"]),
            ("CPU:", cpu_model),
            ("BogoMIPS:", bogomips),
            ("Monitored CPUs:", str(len(logical_cpus_indexes))),
            ("Monitored Disks:", str(len(all_disks))),
            ("Monitored Network Devices:", str(len(all_netdevices))),
        ]
        return monitored_summary

    def generate_monitored_summary(self):
        if len(self.baremetal_logical_cpus_indexes) > 0:
            self.output_page.appendHtmlTable(
                "Monitored System Summary",
                self.__generate_monitored_summary_with_cpus(self.baremetal_logical_cpus_indexes),
            )
        elif len(self.cgroup_logical_cpus_indexes) > 0:
            self.output_page.appendHtmlTable(
                "Monitored System Summary",
                self.__generate_monitored_summary_with_cpus(self.cgroup_logical_cpus_indexes),
            )

    def generate_about_this(self):
        about_this = [
            ("Zoom:", "use left-click and drag"),
            ("Reset view:", "use right-click"),
            ("Generated by", '<a href="https://github.com/f18m/cmonitor">cmonitor</a>'),
        ]
        self.output_page.appendHtmlTable("About this", about_this, div_id="bottom_about_div")


# =======================================================================================================
# MAIN SCRIPT PREPARE DATA
# =======================================================================================================


def load_json_data(infile):
    """
    This function is able to read both JSON files produced by cmonitor_collector and
    compressed JSON.GZ files.
    Moreover this function is also tolerant to unfinished JSON files (i.e. files in which
    cmonitor_collector is still appending data).
    Finally it also performs very basic validation of JSON structure.
    Returns the JSON structure of the document.

    This function is shared between cmonitor_chart.py and cmonitor_statistics.py
    """
    # read the raw .json as text
    try:
        if infile[-8:] == ".json.gz":
            print("Loading gzipped JSON file %s" % infile)
            f = gzip.open(infile, "rb")
            text = f.read()
            f.close()

            # in Python 3.5 the gzip returns a sequence of "bytes" and not a "str"
            if isinstance(text, bytes):
                text = text.decode("utf-8")
        else:
            print("Loading JSON file %s" % infile)
            f = open(infile, "r")
            text = f.read()
            f.close()
    except OSError as err:
        print("Error while opening input JSON file '%s': %s" % (infile, err))
        sys.exit(1)

    # Convert the text to json and extract the stats
    try:
        entry = json.loads(text)  # convert text to JSON
    except json.decoder.JSONDecodeError as e:
        # fix up the end of the file if it is not complete
        if text[-1] == ",":
            # try removing last comma
            text[-1] = " "
        # add the closure of the "samples" array and JSON end-of-object
        entry = json.loads(text + "]}")

    try:
        jheader = entry["header"]
        jdata = entry["samples"]  # removes outer parts so we have a list of snapshot dictionaries
    except:
        print("Unexpected JSON format. Aborting.")
        sys.exit(1)

    # Check if cmonitor_collector version used differs or not:
    try:
        cmonitor_collector_version = jheader["cmonitor"]["version"]
        my_major = VERSION_STRING.split(".")[0]
        cmonitor_collector_major = cmonitor_collector_version.split(".")[0]
        if cmonitor_collector_major != my_major:
            print(
                f"ERROR: the input JSON file has been generated by cmonitor_collector v{cmonitor_collector_version}, which has a different MAJOR version compared to this tool which is v{VERSION_STRING}."
            )
            sys.exit(10)
        elif cmonitor_collector_version != VERSION_STRING:
            print(
                f"WARNING: the input JSON file has been generated by cmonitor_collector v{cmonitor_collector_version}, different than the version of this tool which is v{VERSION_STRING}."
            )
    except KeyError:
        pass
    return entry


def main_process_file(cfg):
    infile = cfg["input_json"]
    outfile = config["output_html"]
    start_time = time.time()

    # load the JSON
    entry = load_json_data(infile)
    jheader = entry["header"]
    jdata = entry["samples"]

    # load some basic fields from the JSON
    monitored_system = "Unknown"
    if "identity" in jheader:
        if "hostname" in jheader["identity"]:
            monitored_system = "host " + jheader["identity"]["hostname"]
    if "custom_metadata" in jheader:
        if "cmonitor_chart_name" in jheader["custom_metadata"]:
            monitored_system = jheader["custom_metadata"]["cmonitor_chart_name"]

    cgroupName = "None"
    if "cgroup_config" in jheader and "name" in jheader["cgroup_config"]:
        cgroupName = jheader["cgroup_config"]["name"]
    if "custom_metadata" in jheader:
        if "cmonitor_chart_name" in jheader["custom_metadata"]:
            cgroupName = "docker/" + jheader["custom_metadata"]["cmonitor_chart_name"]

    sample_template = jdata[0]
    if verbose:
        print("Found %d data samples" % len(jdata))

    print("Opening output file %s" % outfile)
    out_doc = HtmlOutputPage(outfile, "Monitoring data for " + monitored_system)
    graph_generator = CMonitorGraphGenerator(out_doc, jheader, jdata)

    # HTML HEAD -- all of these functions below generate JS code to be put inside the <HEAD>
    graph_generator.output_page.startHtmlHead()

    # baremetal stats:
    graph_generator.generate_baremetal_cpus()
    graph_generator.generate_baremetal_memory()
    graph_generator.generate_baremetal_network_traffic()
    graph_generator.generate_baremetal_disks_io()
    graph_generator.generate_baremetal_avg_load()

    # cgroup stats:
    graph_generator.generate_cgroup_cpus()
    graph_generator.generate_cgroup_memory()
    graph_generator.generate_cgroup_topN_procs(config["top_scorer"], config["thread_filter"])
    graph_generator.generate_cgroup_network_traffic()

    graph_generator.generate_config_viewer()

    # HTML BODY -- now we start actual HTML body which are just a few tables with buttons
    #              that invoke the JS code produced earlier inside the <HEAD>
    graph_generator.output_page.startHtmlBody(cgroupName, monitored_system)

    graph_generator.generate_monitoring_summary()
    graph_generator.generate_monitored_summary()
    graph_generator.generate_about_this()

    graph_generator.output_page.endHtmlBody()

    end_time = time.time()
    print("Completed processing of input JSON file of %d samples in %.3fsec. HTML output file is ready." % (len(jdata), end_time - start_time))


# =======================================================================================================
# MAIN
# =======================================================================================================


def usage():
    """Provides commandline usage"""
    print("cmonitor_chart version {}".format(VERSION_STRING))
    print("Utility to post-process data recorded by 'cmonitor_collector' and")
    print("create a self-contained HTML file for visualizing that data.")
    print("Typical usage:")
    print("  %s --input=output_from_cmonitor_collector.json [--output=myreport.html]" % sys.argv[0])
    print("Required parameters:")
    print("  -i, --input=<file.json>    The JSON file to analyze.")
    print("Main options:")
    print("  -h, --help                 (this help)")
    print("  -v, --verbose              Be verbose.")
    print("  -o, --output=<file.html>   The name of the output HTML file.")
    print("  -u, --utc                  Plot data using UTC timestamps instead of local timezone.")
    print("  -t, --top-scorer=N         Plot the N most-CPU-hungry processes/threads. Default is 20. Zero means plot all.")
    print("  -f, --filter=<tname>       Plot only the threads filtered by the selected substring . Default is None.")
    print("      --version              Print version and exit.")
    sys.exit(0)


def parse_command_line():
    """Parses the command line and returns the configuration as dictionary object."""
    try:
        opts, remaining_args = getopt.getopt(
            sys.argv[1:],
            "hvvut",
            [
                "help",
                "verbose",
                "version",
                "output=",
                "input=",
                "utc",
                "top-scorer=",
                "filter=",
            ],
        )
    except getopt.GetoptError as err:
        # print help information and exit:
        print(str(err))  # will print something like "option -a not recognized"
        usage()  # will exit program

    global verbose
    global g_datetime
    input_json = ""
    output_html = ""
    top_scorer = 20
    thread_filter = ""
    for o, a in opts:
        if o in ("-i", "--input"):
            input_json = a
        elif o in ("-o", "--output"):
            output_html = a
        elif o in ("-h", "--help"):
            usage()
        elif o in ("-v", "--verbose"):
            verbose = True
        elif o in ("-u", "--utc"):
            # instead of default 'datetime' which means local timezone
            g_datetime = "UTC"
        elif o in ("-t", "--top-scorer"):
            try:
                top_scorer = int(a)
            except:
                print("Invalid argument for --top-scorer. Provide a number.")
                sys.exit(1)
        elif o in ("-f", "--filter"):
            thread_filter = a
        elif o in ("--version"):
            print("{}".format(VERSION_STRING))
            sys.exit(0)
        else:
            assert False, "unhandled option " + o + a

    if input_json == "":
        print("Please provide --input option (it is a required option)")
        sys.exit(os.EX_USAGE)

    if output_html == "":
        if input_json[-8:] == ".json.gz":
            output_html = input_json[:-8] + ".html"
        elif input_json[-5:] == ".json":
            output_html = input_json[:-5] + ".html"
        else:
            output_html = input_json + ".html"

    abs_input_json = input_json
    if not os.path.isabs(input_json):
        abs_input_json = os.path.join(os.getcwd(), input_json)

    return {
        "input_json": input_json,
        "output_html": output_html,
        "top_scorer": top_scorer,
        "thread_filter": thread_filter,
    }


# =======================================================================================================
# MAIN
# =======================================================================================================

if __name__ == "__main__":
    config = parse_command_line()
    main_process_file(config)
